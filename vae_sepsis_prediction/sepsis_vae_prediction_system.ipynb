{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16bffb23",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ¥ VAE-Based Sepsis Prediction System\n",
    "## Generative AI for Early Sepsis Detection with Ethics & Responsibility\n",
    "\n",
    "This notebook implements a complete **Variational Autoencoder (VAE)** based system for predicting sepsis risk from Electronic Health Records (EHR). \n",
    "\n",
    "### Key Features:\n",
    "1. **Generative AI (VAE)**: Learns latent representations of health states and detects anomalies.\n",
    "2. **Uncertainty Quantification**: Uses Monte Carlo sampling to provide confidence intervals.\n",
    "3. **Synthetic Patient Generation**: Generates realistic synthetic patients for data augmentation.\n",
    "4. **AI Ethics Framework**: Analyzes fairness and bias across demographics (Age, Gender).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd3e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "from typing import Tuple, Dict, List, Optional\n",
    "import time\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb554472",
   "metadata": {},
   "source": [
    "## 1. VAE Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SepsisVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational Autoencoder for Sepsis Risk Prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int = 17, latent_dim: int = 8, hidden_dims: list = [64, 32, 16], dropout_rate: float = 0.2):\n",
    "        super(SepsisVAE, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_layers = []\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            encoder_layers.extend([nn.Linear(prev_dim, hidden_dim), nn.BatchNorm1d(hidden_dim), nn.ReLU(), nn.Dropout(dropout_rate)])\n",
    "            prev_dim = hidden_dim\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        \n",
    "        # Latent distribution\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        decoder_layers = []\n",
    "        prev_dim = latent_dim\n",
    "        for hidden_dim in reversed(hidden_dims):\n",
    "            decoder_layers.extend([nn.Linear(prev_dim, hidden_dim), nn.BatchNorm1d(hidden_dim), nn.ReLU(), nn.Dropout(dropout_rate)])\n",
    "            prev_dim = hidden_dim\n",
    "        decoder_layers.append(nn.Linear(hidden_dims[0], input_dim))\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "        \n",
    "        # Sepsis Classifier (from latent space)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32), nn.ReLU(), nn.Dropout(dropout_rate),\n",
    "            nn.Linear(32, 16), nn.ReLU(), nn.Dropout(dropout_rate),\n",
    "            nn.Linear(16, 1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        risk = self.classifier(z)\n",
    "        return x_recon, mu, logvar, risk\n",
    "\n",
    "    def predict_sepsis(self, x, n_samples=10):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            mu, logvar = self.encode(x)\n",
    "            risks = []\n",
    "            for _ in range(n_samples):\n",
    "                z = self.reparameterize(mu, logvar)\n",
    "                risks.append(self.classifier(z))\n",
    "            risks = torch.stack(risks)\n",
    "            return {\n",
    "                'risk_mean': risks.mean(0),\n",
    "                'risk_std': risks.std(0),\n",
    "                'risk_lower': torch.quantile(risks, 0.025, 0),\n",
    "                'risk_upper': torch.quantile(risks, 0.975, 0)\n",
    "            }\n",
    "\n",
    "    def generate_synthetic_patients(self, n, sepsis=None):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(n, self.latent_dim).to(device)\n",
    "            if sepsis is not None:\n",
    "                z = z + (1.0 if sepsis else -1.0)\n",
    "            return self.decode(z)\n",
    "\n",
    "def vae_loss_function(x_recon, x, mu, logvar, pred, true, beta=1.0, class_weight=2.0):\n",
    "    recon_loss = F.mse_loss(x_recon, x)\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / mu.size(0)\n",
    "    class_loss = F.binary_cross_entropy(pred, true.unsqueeze(1))\n",
    "    return recon_loss + beta * kl_loss + class_weight * class_loss, recon_loss, kl_loss, class_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f367d1",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda21ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EHRDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.FloatTensor(x)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, idx): return self.x[idx], self.y[idx]\n",
    "\n",
    "def get_simulated_data(n=5000):\n",
    "    np.random.seed(42)\n",
    "    # Vital signs and labs\n",
    "    data = pd.DataFrame({\n",
    "        'age': np.random.normal(65, 15, n).clip(18, 100),\n",
    "        'gender': np.random.choice([0, 1], n),\n",
    "        'hr': np.random.normal(85, 15, n).clip(40, 180),\n",
    "        'rr': np.random.normal(16, 4, n).clip(8, 40),\n",
    "        'temp': np.random.normal(37.0, 0.8, n).clip(35, 41),\n",
    "        'sbp': np.random.normal(120, 20, n).clip(70, 200),\n",
    "        'dbp': np.random.normal(75, 15, n).clip(40, 130),\n",
    "        'spo2': np.random.normal(96, 3, n).clip(70, 100),\n",
    "        'wbc': np.random.normal(9, 3, n).clip(2, 30),\n",
    "        'lac': np.random.normal(1.5, 1.0, n).clip(0.5, 10),\n",
    "        'crea': np.random.normal(1.0, 0.5, n).clip(0.5, 5),\n",
    "        'plt': np.random.normal(250, 80, n).clip(50, 500),\n",
    "        'bili': np.random.normal(0.8, 0.5, n).clip(0.2, 5)\n",
    "    })\n",
    "    # Derived features\n",
    "    data['map'] = (data['sbp'] + 2 * data['dbp']) / 3\n",
    "    data['pp'] = data['sbp'] - data['dbp']\n",
    "    data['si'] = data['hr'] / data['sbp']\n",
    "    data['age_norm'] = data['age'] / 100\n",
    "    \n",
    "    # sepsis label\n",
    "    score = (data['hr']>100)*0.2 + (data['lac']>2)*0.3 + (data['sbp']<100)*0.2 + np.random.normal(0, 0.1, n)\n",
    "    data['sepsis'] = (score > np.percentile(score, 85)).astype(int)\n",
    "    \n",
    "    return data\n",
    "\n",
    "df = get_simulated_data()\n",
    "X = df.drop('sepsis', axis=1).values\n",
    "y = df['sepsis'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test, df_train, df_test = train_test_split(X, y, df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(EHRDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(EHRDataset(X_test, y_test), batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Data ready. Train size: {len(X_train)}, Test size: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde2d0d",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SepsisVAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 50\n",
    "history = {'loss': [], 'recon': [], 'kl': [], 'class': []}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_losses = [0]*4\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        x_recon, mu, logvar, risk = model(x)\n",
    "        loss, recon, kl, cl = vae_loss_function(x_recon, x, mu, logvar, risk, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses[0] += loss.item()\n",
    "        epoch_losses[1] += recon.item()\n",
    "        epoch_losses[2] += kl.item()\n",
    "        epoch_losses[3] += cl.item()\n",
    "        \n",
    "    for i, k in enumerate(history.keys()):\n",
    "        history[k].append(epoch_losses[i] / len(train_loader))\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {history['loss'][-1]:.4f}\")\n",
    "\n",
    "# Plot History\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['loss'], label='Total Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['class'], label='Classification Loss')\n",
    "plt.title('Clinical Prediction Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6388b69",
   "metadata": {},
   "source": [
    "## 4. AI Ethics and Responsibility Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_fairness(model, X_test, y_test, df_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        results = model.predict_sepsis(torch.FloatTensor(X_test).to(device))\n",
    "        preds = (results['risk_mean'].cpu().numpy() > 0.5).astype(int)\n",
    "        \n",
    "    df_results = df_test.copy()\n",
    "    df_results['pred'] = preds\n",
    "    df_results['label'] = y_test\n",
    "    \n",
    "    print(\"--- Fairness Analysis ---\")\n",
    "    # Gender Fairness\n",
    "    for g in [0, 1]:\n",
    "        mask = df_results['gender'] == g\n",
    "        acc = (df_results[mask]['pred'] == df_results[mask]['label']).mean()\n",
    "        gender_name = \"Male\" if g == 1 else \"Female\"\n",
    "        print(f\"Accuracy for {gender_name}: {acc:.2%}\")\n",
    "    \n",
    "    # Age Fairness\n",
    "    df_results['age_group'] = pd.cut(df_results['age'], bins=[0, 40, 65, 100], labels=['Young', 'Middle', 'Senior'])\n",
    "    for group in df_results['age_group'].unique():\n",
    "        mask = df_results['age_group'] == group\n",
    "        acc = (df_results[mask]['pred'] == df_results[mask]['label']).mean()\n",
    "        print(f\"Accuracy for {group}: {acc:.2%}\")\n",
    "\n",
    "analyze_fairness(model, X_test, y_test, df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9885b756",
   "metadata": {},
   "source": [
    "## 5. Generative AI Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate 5 synthetic \"High Risk\" patient clinical profiles\n",
    "synthetic_patients = model.generate_synthetic_patients(5, sepsis=True).cpu().numpy()\n",
    "synthetic_df = pd.DataFrame(scaler.inverse_transform(synthetic_patients), columns=df.columns[:-1])\n",
    "\n",
    "print(\"Generated Synthetic Sepsis Patient Profiles:\")\n",
    "display(synthetic_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bbfa9e",
   "metadata": {},
   "source": [
    "## 6. Uncertainty Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3944ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select a random patient and show prediction with confidence interval\n",
    "idx = np.random.randint(len(X_test))\n",
    "patient = torch.FloatTensor(X_test[idx:idx+1]).to(device)\n",
    "pred = model.predict_sepsis(patient, n_samples=50)\n",
    "\n",
    "print(f\"Patient ID: {idx}\")\n",
    "print(f\"Predicted Sepsis Risk: {pred['risk_mean'].item():.1%}\")\n",
    "print(f\"Confidence Interval: [{pred['risk_lower'].item():.1%}, {pred['risk_upper'].item():.1%}]\")\n",
    "print(f\"Model Uncertainty (Std): {pred['risk_std'].item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
